{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da61be2a",
   "metadata": {},
   "source": [
    "### Workshop series, Ko√ß University, Turkey, 11-12 April 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70bc56f",
   "metadata": {},
   "source": [
    "##  [Introduction to Computational Social Science methods with Python](https://socialcomquant.ku.edu.tr/intro-to-css-methods-with-python/)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "71218328",
   "metadata": {},
   "source": [
    "# Workshop 2: Introduction to network analysis with Python - Part II\n",
    "\n",
    "**Description**: Computational Social Science is often concerned with the traces of human behavior like those left by uses of social media, messaging services, or cell phones. Such digital behavioral data is genuinely relational and can, therefore, be studied using the formal techniques of network analysis. The basic units of networks called nodes can be actors (e.g., users), communicative symbols (e.g., hashtags), or even transactions (e.g., tweets). By focusing on the edges (relations) among nodes, network analysis is capable of creating insights that are not possible by merely doing statistics on the nodes and their attributes. In the workshop, we will give an introduction to how network data should be organized, how networks can be created in Python, and how they can be analyzed on three levels. On the micro level, we will introduce centrality analysis which results in numerical descriptions of nodes. On the meso level, we will introduce community detection, which results in sets of nodes that form groups or clusters. On the macro level, we will introduce measures that describe homophily, assortativity of, the network in its entirety. We will be using network data from the Copenhagen Networks Study, which describes four different types of social relations among students over time. The workshop will alternate between live-coding demonstrations and periods in which participants apply that knowledge in context, both using Jupyter Notebooks. The software we will be using is NetworkX, a standard Python library that is simple to understand, provides a breadth of options and has a large user community.\n",
    "\n",
    "**Target group**: Undergraduate, master students, doctoral candidates, and experienced researchers who want to get introduced to the practice of Computational Social Science.\n",
    "\n",
    "**Requirements**: Participants are expected to know the basics of Python and have at least some experience using it. For the workshops, participants should bring a running system on which they can execute Jupyter Notebooks. We will be using Python 3.9 and several standard libraries that are part of the Anaconda 2022.10 distribution or can be installed on top of that. A list of libraries and versions of these libraries that participants should import will be circulated before the workshops. We recommend that participants install Anaconda 2022.10. Feel free to also work in a cloud-like Google Colab. Consult [this link](https://github.com/gesiscss/css_methods_python/blob/main/a_introduction/1_computing_environment.ipynb) for more detailed instructions on how to set up your computing environment.\n",
    "\n",
    "**Lecturers**: Dr. Haiko Lietz is a postdoctoral researcher in the Computational Social Science department at GESIS - Leibniz Institute for the Social Sciences. His research interests are in computational sociology, network science, and complexity science. Dr. N. Gizem Bacaksizlar Turbic is a postdoctoral researcher in the Computational Social Science departments at RWTH Aachen University and GESIS - Leibniz Institute for the Social Sciences. Her research areas include complex adaptive systems and social and political networks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed1d0709",
   "metadata": {},
   "source": [
    "## Documentation of Networkx 2.8.4\n",
    "\n",
    "https://networkx.org/documentation/networkx-2.8.4/reference/index.html"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7a506d5e",
   "metadata": {},
   "source": [
    "## Network analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "161caa5f",
   "metadata": {},
   "source": [
    "### Centrality measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b8ad9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "nx.__version__\n",
    "import pandas as pd\n",
    "from operator import itemgetter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a9994e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we will focus on the directed network of sms data first\n",
    "D_sms = nx.read_gml('./data/D_sms_week1_lcc.gml')\n",
    "D_sms = nx.convert_node_labels_to_integers(D_sms, first_label=0, ordering='default', label_attribute=None)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4a67efb3",
   "metadata": {},
   "source": [
    "#### Degree centrality\n",
    "The __degree__ is the number of ties a node has. The __degree centrality__ for a node _v_ is the fraction of nodes it is connected to. It measures potential communication activity. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61a39ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "degree_cent = nx.degree_centrality(D_sms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91827268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the first five nodes of the degree centrality dictionary\n",
    "list(degree_cent.items())[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f6c496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the top five nodes with higher degree centrality\n",
    "dict(sorted(degree_cent.items(), key = itemgetter(1), reverse = True)[:5])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b202a967",
   "metadata": {},
   "source": [
    "#### In-degree centrality\n",
    "The __in-degree centrality__ for a node _v_ is the fraction of nodes its incoming edges are connected to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f5f7b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_degree_cent = nx.in_degree_centrality(D_sms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba03b442",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the first five nodes of the in_degree centrality dictionary\n",
    "list(in_degree_cent.items())[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c89f200",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the top five nodes with higher in_degree centrality\n",
    "dict(sorted(in_degree_cent.items(), key = itemgetter(1), reverse = True)[:5])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "87ede516",
   "metadata": {},
   "source": [
    "#### Out-degree centrality\n",
    "The __out-degree centrality__ for a node _v_ is the fraction of nodes its outgoing edges are connected to."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de401edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_degree_cent = nx.out_degree_centrality(D_sms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9a188f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the first five nodes of the out_degree centrality dictionary\n",
    "list(out_degree_cent.items())[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6dc815c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the top five nodes with higher out_degree centrality\n",
    "dict(sorted(out_degree_cent.items(), key = itemgetter(1), reverse = True)[:5])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "310bcfce",
   "metadata": {},
   "source": [
    "#### PageRank \n",
    "__PageRank__ counts the number and quality of links to a node to determine a rough estimate of how important the node is. The underlying assumption is that more important nodes are likely to receive more edges from other nodes.\n",
    "\n",
    "Note: Undirected graphs will be converted to a directed graph with two directed edges for each undirected edge.\n",
    "\n",
    "More details here https://networkx.github.io/documentation/stable/reference/algorithms/generated/networkx.algorithms.link_analysis.pagerank_alg.pagerank.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb891d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "pagerank_cent = nx.pagerank(D_sms, alpha=0.85, personalization=None, max_iter=100, tol=1e-06, nstart=None, weight='weight', dangling=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9654737e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the first five nodes of the pagerank centrality dictionary\n",
    "list(pagerank_cent.items())[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff34c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the top five nodes with higher pagerank centrality\n",
    "dict(sorted(pagerank_cent.items(), key = itemgetter(1), reverse = True)[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ff0db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae69530",
   "metadata": {},
   "outputs": [],
   "source": [
    "D_sms.degree(weight='weight')[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40d839cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "[node for node in nx.neighbors(D_sms, n=4)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "15fbf47a",
   "metadata": {},
   "source": [
    "##### Correlation of centrality measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc993d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodelist_cent = pd.DataFrame()\n",
    "nodelist_cent['degree'] = degree_cent.values()\n",
    "nodelist_cent['in_degree'] = in_degree_cent.values()\n",
    "nodelist_cent['out_degree'] = out_degree_cent.values()\n",
    "nodelist_cent['pagerank'] = pagerank_cent.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22d244fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodelist_cent.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489806c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = (1 - nodelist_cent.corr()).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2226a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import MDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc540fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mds = MDS(n_components=2, random_state=42, dissimilarity='precomputed')\n",
    "pos = mds.fit(data).embedding_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5c5931",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(pos[:, 0], pos[:, 1])\n",
    "for i in range(0, len(nodelist_cent.columns)):\n",
    "    plt.text(pos[i, 0], pos[i, 1], nodelist_cent.columns[i])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5dea20ce",
   "metadata": {},
   "source": [
    "### Exercise 2: Add closeness and betweenness centralities, then update the correlation analysis\n",
    "\n",
    "__Closeness centrality__ of a node _u_ is the reciprocal of the average shortest path distance to _u_ over all _n-1_ reachable nodes. \n",
    "\n",
    "`closeness_centrality(G, u=None, distance=None)` where `u` is node for which centrality should be calculated and `distance` edge attribute name that should be used to calculate distance in shortest pathes.\n",
    "\n",
    "__Betweenness centrality__ of a node _v_ is the sum of the fraction of all-pairs shortest paths that pass through _v_.\n",
    "\n",
    "`betweenness_centrality(G, k=None, normalized=True, weight=None, endpoints=False, seed=None)` where `k` size of random samples to estimate betweenness, `weight` is the name of the attribute that should be used as distance metric and `seed` is random number generation state. \n",
    "\n",
    "More detail here https://networkx.github.io/documentation/stable/reference/algorithms/generated/networkx.algorithms.centrality.betweenness_centrality.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e378f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "closeness_cent = nx.closeness_centrality(D_sms, distance = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d64ef8",
   "metadata": {},
   "outputs": [],
   "source": [
    "betweenness_cent = nx.betweenness_centrality(D_sms, normalized=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3cf78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodelist_cent['closeness'] = closeness_cent.values()\n",
    "nodelist_cent['betweenness'] = betweenness_cent.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4241211",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodelist_cent.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689cad46",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = (1 - nodelist_cent.corr()).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbd8761",
   "metadata": {},
   "outputs": [],
   "source": [
    "mds = MDS(n_components=2, random_state=42, dissimilarity='precomputed')\n",
    "pos = mds.fit(new_data).embedding_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9ca228",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(pos[:, 0], pos[:, 1])\n",
    "for i in range(0, len(nodelist_cent.columns)):\n",
    "    plt.text(pos[i, 0], pos[i, 1], nodelist_cent.columns[i])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dd9f7c58",
   "metadata": {},
   "source": [
    "### Community detection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3d4aee9e",
   "metadata": {},
   "source": [
    "For community detection, we move to networks from our bluetooth exercises."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba231478",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c3b6e69c",
   "metadata": {},
   "source": [
    "Note: the gml files we have didn't have attributes so I couldn't work on them. Instead just for a placeholder, I started with this pickle file below. After we decide on the versions, we can change these cells below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24af5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# G_bt_unlayered = nx.read_gml('./data/D_sms_week1_lcc.gml', destringizer=int)\n",
    "with open('./data/G_cns_bt_f2f_p_lcc_unlayered.pickle', 'rb') as f:\n",
    "    G_bt_unlayered = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6684d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodelist_bt = pd.DataFrame(index=G_bt_unlayered.nodes())\n",
    "nodelist_bt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0bf632b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from networkx.algorithms.community import louvain_communities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f66044",
   "metadata": {},
   "outputs": [],
   "source": [
    "louvain = louvain_communities(G=G_bt_unlayered, weight='weight', seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ae596b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_partition(communities):\n",
    "    return dict(sorted({node: community for community in range(len(communities)) for node in list(communities[community])}.items()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84bddaa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodelist_bt['louvain_week1'] = get_partition(louvain).values()\n",
    "nodelist_bt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04f3341",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.get_node_attributes(G_bt_unlayered, name = 'pos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06ac924",
   "metadata": {},
   "outputs": [],
   "source": [
    "G_bt_unlayered.nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2708381a",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.draw(\n",
    "    G = G_bt_unlayered, \n",
    "    pos = nx.get_node_attributes(G=G_bt_unlayered, name='pos'), \n",
    "    node_size = 40, \n",
    "    node_color = nodelist_bt['louvain_week1'], \n",
    "    cmap = plt.cm.rainbow\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "995e3fc8",
   "metadata": {},
   "source": [
    "### Exercise 3: Try Louvain method on the snapshot 4's graph"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "edcfd36e",
   "metadata": {},
   "source": [
    "Will add when we have snapshot 4 ready with attributes or pickle version.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d642f8dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fda3383",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32354ce1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f49deb68",
   "metadata": {},
   "source": [
    "### Homophily\n",
    "\n",
    "Assortativity helps analysing pattern of connections in networks. To analyze homophily (if people tend to connect to similar people), we can use attribute assortativity coefficient and attribute mixing matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12b040a",
   "metadata": {},
   "source": [
    "The sex categories are 0: male; 1: female; 2: unknown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b78f81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.attribute_assortativity_coefficient(G=G_bt_unlayered, attribute='sex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d3dee34",
   "metadata": {},
   "outputs": [],
   "source": [
    "nx.attribute_mixing_matrix(G=G_bt_unlayered, attribute='sex', normalized=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184656e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3fc439",
   "metadata": {},
   "outputs": [],
   "source": [
    "def attribute_density_matrix(G, attribute):\n",
    "    l = [data[attribute] for v, data in G.nodes(data=True)]\n",
    "    counts = list(Counter(l).values())\n",
    "    a = np.empty(shape=(len(counts), len(counts)))\n",
    "    for i in range(len(counts)):\n",
    "        for j in range(len(counts)):\n",
    "            if i == j:\n",
    "                a[i, j] = counts[i] * (counts[j] - 1)\n",
    "            else:\n",
    "                a[i, j] = counts[i] * counts[j]\n",
    "    return nx.attribute_mixing_matrix(G=G, attribute=attribute, normalized=False) / a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "582dc2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_bt = nx.density(G=G_bt_unlayered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858ae3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_bt_sex = attribute_density_matrix(G=G_bt_unlayered, attribute='sex').round(4)\n",
    "p_bt_sex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd691b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "(p_bt_sex / p_bt).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3256cc39",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
