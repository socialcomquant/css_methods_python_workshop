{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"4_topic-models.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMGpVLwkxUI27uAhr/AVZQ9"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"Yvn9GDQu2rDk"},"source":["# Topic Models"]},{"cell_type":"markdown","metadata":{"id":"_3ndXx1A0KzE"},"source":["We begin by fetching the **20 Newsgroups** [dataset](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.fetch_20newsgroups.html?highlight=fetch_20newsgroups#sklearn.datasets.fetch_20newsgroups) and take the first 2000 articles."]},{"cell_type":"code","metadata":{"id":"2V4QbDFmhBsB","executionInfo":{"status":"ok","timestamp":1632407162335,"user_tz":-120,"elapsed":16583,"user":{"displayName":"Arnim Bleier","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj9FpxNjfcpe25EhN8fFktoI2VgFpDD6JYapnF1V-A=s64","userId":"13209896281456228043"}},"outputId":"d9206bcc-b033-4487-f725-f531ec7b0f91","colab":{"base_uri":"https://localhost:8080/"}},"source":["from sklearn.datasets import fetch_20newsgroups\n","data, _ = fetch_20newsgroups(shuffle=True, random_state=1,\n","                             remove=('headers', 'footers', 'quotes'),\n","                             return_X_y=True)\n","\n","data = data[:2000]"],"execution_count":1,"outputs":[{"output_type":"stream","name":"stderr","text":["Downloading 20news dataset. This may take a few minutes.\n","Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"]}]},{"cell_type":"markdown","metadata":{"id":"jIkqcS553yig"},"source":["**Exercise:** let's again use the [CountVectorizer](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html) but allow only non stop words words that occur at least 5 times in the corpus, are in a maximum of 30% of the documents, contain only letters a-z, and have a minimum length of 4 as well as a maximum length of 10 characters. Hint: for some of the requirements we can use the `token_pattern = '[a-zA-Z]{4,10}' `."]},{"cell_type":"code","metadata":{"id":"Gf-ThvtFhPdT"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"J47ryxft7zAi"},"source":["Size of our vocabulary"]},{"cell_type":"code","metadata":{"id":"7cKOBiaVnfmE"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"y5ZGd8Qg8ED1"},"source":["**Exercise:** Next let's import [LatentDirichletAllocation](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html) `from sklearn.decomposition` and initialize it to estimate 50 topics."]},{"cell_type":"code","metadata":{"id":"LKGWwVGciNrO"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MQCv_2MYivGU"},"source":["lda.fit(X_bag_of_words)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ofYtVafz9ilZ"},"source":["We then need some boilerplate code to display the top words per topic."]},{"cell_type":"code","metadata":{"id":"NIqBUtWAwLKU"},"source":["def display_topics(model, feature_names, no_top_words):\n","    for topic_idx, topic in enumerate(model.components_):\n","        print (\"Topic %d:\" % (topic_idx))\n","        print (\" \".join([feature_names[i]\n","                        for i in topic.argsort()[:-no_top_words - 1:-1]]))\n","# code from https://gist.github.com/aneesha/440f3d104415c6ae21851a062f3880d8#file-displaytopics-py"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bg8cvBBHjVE_"},"source":["display_topics(lda, vectorizer.get_feature_names(), 10)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RjVfbWCj-PkM"},"source":["A more in depth review and comparison with [NMF](https://scikit-learn.org/stable/modules/generated/sklearn.decomposition.NMF.html#sklearn.decomposition.NMF) is available in the scikit-learn [documentation](https://scikit-learn.org/stable/auto_examples/applications/plot_topics_extraction_with_nmf_lda.html). A popular alternative is [GENSIM](https://radimrehurek.com/gensim/)."]}]}